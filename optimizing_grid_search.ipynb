{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from matplotlib.pyplot import *\n",
    "# Suppress warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score, average_precision_score, precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from  matplotlib.ticker import PercentFormatter\n",
    "style.use('ggplot')\n",
    "\n",
    "\n",
    "file_path = 'Consumer_Complaints.csv'\n",
    "consumer_data = pd.read_csv(file_path,error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "#consumer_data=consumer_data.dropna()\n",
    "consumer_data.Product=consumer_data.Product.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "consumer_data.Product=consumer_data.Product.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "consumer_data.Issue=consumer_data.Issue.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "\n",
    "consumer_data.columns =consumer_data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_').str.replace('?', '')\n",
    "consumer_data.sub_issue=consumer_data.sub_issue.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "consumer_data.sub_product=consumer_data.sub_product.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "consumer_data = consumer_data.drop_duplicates(consumer_data.columns, keep='last')\n",
    "consumer_data['date_received'] =[datetime.strptime(x, '%m/%d/%Y') for x in consumer_data['date_received'] ]\n",
    "consumer_data['date_sent_to_company'] =[datetime.strptime(x, '%m/%d/%Y') for x in consumer_data['date_sent_to_company'] ]\n",
    "\n",
    "\n",
    "dispute_data=consumer_data[(consumer_data['consumer_disputed']=='Yes')|(consumer_data['consumer_disputed']=='No')]\n",
    "#dispute_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####count companies disputes and create dictionary\n",
    "company_counts=dispute_data['company'].value_counts()\n",
    "dfcompany_counts = pd.DataFrame({'counts':company_counts.values,'dic_company':company_counts.index,'companies':company_counts.index,})\n",
    "\n",
    "dfcompany_counts['dic_company'] =[\"unique\" if x==1 else dfcompany_counts['dic_company'].iloc[i] for i,x in enumerate(dfcompany_counts['counts'])]\n",
    "dfcompany_counts['dic_company'] =[\"petite\" if (x>1 and x<100) else dfcompany_counts['dic_company'].iloc[i] for i,x in enumerate(dfcompany_counts['counts'])]\n",
    "dfcompany_counts['dic_company'] =['small' if (x>100 and x<1000)  else dfcompany_counts['dic_company'].iloc[i] for i,x in enumerate(dfcompany_counts['counts'])]\n",
    "dfcompany_counts['dic_company'] =['medium' if (x>=1000 and x<5000) else dfcompany_counts['dic_company'].iloc[i] for i,x in enumerate(dfcompany_counts['counts'])]\n",
    "\n",
    "company_dict = dict(zip(dfcompany_counts.companies, dfcompany_counts.dic_company))\n",
    " \n",
    "dispute_data['company_code']=dispute_data['company'].map(company_dict)\n",
    "\n",
    "#sns.catplot(y=\"company_code\", hue=\"consumer_disputed\", kind=\"count\",data=dispute_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispute_data=pd.get_dummies(data=dispute_data, columns=['product'])\n",
    "dispute_data=pd.get_dummies(data=dispute_data, columns=['issue'])\n",
    "#dispute_data=pd.get_dummies(data=dispute_data, columns=['sub_product'])\n",
    "#dispute_data=pd.get_dummies(data=dispute_data, columns=['sub_issue'])\n",
    "dispute_data=pd.get_dummies(data=dispute_data, columns=['company_public_response'])\n",
    "dispute_data=pd.get_dummies(data=dispute_data, columns=['company_code'])\n",
    "dispute_data=pd.get_dummies(data=dispute_data, columns=['consumer_consent_provided'])\n",
    "dispute_data=pd.get_dummies(data=dispute_data, columns=['submitted_via'])\n",
    "\n",
    "dispute_data=pd.get_dummies(data=dispute_data, columns=['company_response_to_consumer'])\n",
    "dispute_data=pd.get_dummies(data=dispute_data, columns=['timely_response'])\n",
    "dispute_data=pd.get_dummies(data=dispute_data, columns=['consumer_disputed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dispute_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['product_bank_account_or_service',  'product_checking_or_savings_account',  'product_consumer_loan',  'product_credit_card',  'product_credit_reporting',  'product_debt_collection',  'product_money_transfers',  'product_mortgage',  'product_other_financial_service',  'product_payday_loan',  'product_prepaid_card',  'product_student_loan',  'product_virtual_currency',  'issue_account_opening,_closing,_or_management',  'issue_account_terms_and_changes',  'issue_adding_money',  'issue_advertising,_marketing_or_disclosures',  'issue_advertising_and_marketing',  'issue_application,_originator,_mortgage_broker',  'issue_application_processing_delay',  'issue_applied_for_loan/did_not_receive_money',  'issue_apr_or_interest_rate',  'issue_arbitration',  'issue_balance_transfer',  'issue_balance_transfer_fee',  'issue_bankruptcy',  'issue_billing_disputes',  'issue_billing_statement',  \"issue_can't_contact_lender\",  \"issue_can't_repay_my_loan\",  \"issue_can't_stop_charges_to_bank_account\",  'issue_cash_advance',  'issue_cash_advance_fee',  'issue_charged_bank_acct_wrong_day_or_amt',  \"issue_charged_fees_or_interest_i_didn't_expect\",  'issue_closing/cancelling_account',  'issue_collection_debt_dispute',  'issue_collection_practices',  'issue_communication_tactics',  \"issue_cont'd_attempts_collect_debt_not_owed\",  'issue_convenience_checks',  'issue_credit_card_protection_/_debt_protection',  'issue_credit_decision_/_underwriting',  'issue_credit_determination',  'issue_credit_line_increase/decrease',  'issue_credit_monitoring_or_identity_protection',  'issue_credit_reporting',  \"issue_credit_reporting_company's_investigation\",  'issue_customer_service/customer_relations',  'issue_customer_service_/_customer_relations',  'issue_dealing_with_my_lender_or_servicer',  'issue_delinquent_account',  'issue_deposits_and_withdrawals',  'issue_disclosure_verification_of_debt',  'issue_disclosures',  'issue_excessive_fees',  'issue_false_statements_or_representation',  'issue_fees',  'issue_forbearance_/_workout_plans',  'issue_fraud_or_scam',  'issue_getting_a_loan',  'issue_identity_theft_/_fraud_/_embezzlement',  'issue_improper_contact_or_sharing_of_info',  'issue_improper_use_of_my_credit_report',  'issue_incorrect/missing_disclosures_or_info',  'issue_incorrect_exchange_rate',  'issue_incorrect_information_on_credit_report',  'issue_late_fee',  'issue_lender_damaged_or_destroyed_property',  'issue_lender_damaged_or_destroyed_vehicle',  'issue_lender_repossessed_or_sold_the_vehicle',  'issue_lender_sold_the_property',  'issue_loan_modification,collection,foreclosure',  'issue_loan_servicing,_payments,_escrow_account',  'issue_lost_or_stolen_check',  'issue_lost_or_stolen_money_order',  'issue_making/receiving_payments,_sending_money',  'issue_managing,_opening,_or_closing_account',  'issue_managing_an_account',  'issue_managing_the_line_of_credit',  'issue_managing_the_loan_or_lease',  'issue_money_was_not_available_when_promised',  'issue_opening_an_account',  'issue_other',  'issue_other_fee',  'issue_other_service_issues',  'issue_other_transaction_issues',  'issue_overdraft,_savings_or_rewards_features',  'issue_overlimit_fee',  'issue_payment_to_acct_not_credited',  'issue_payoff_process',  'issue_privacy',  'issue_problems_caused_by_my_funds_being_low',  'issue_problems_when_you_are_unable_to_pay',  \"issue_received_a_loan_i_didn't_apply_for\",  'issue_repaying_your_loan',  'issue_rewards',  'issue_sale_of_account',  'issue_settlement_process_and_costs',  'issue_shopping_for_a_line_of_credit',  'issue_shopping_for_a_loan_or_lease',  'issue_struggling_to_pay_mortgage',  'issue_taking/threatening_an_illegal_action',  'issue_taking_out_the_loan_or_lease',  'issue_transaction_issue',  'issue_trouble_during_payment_process',  'issue_unable_to_get_credit_report/credit_score',  'issue_unauthorized_transactions/trans._issues',  'issue_unexpected/other_fees',  'issue_unsolicited_issuance_of_credit_card',  'issue_using_a_debit_or_atm_card',  'issue_wrong_amount_charged_or_received',  'company_public_response_Company believes complaint caused principally by actions of third party outside the control or direction of the company',  'company_public_response_Company believes complaint is the result of an isolated error',  'company_public_response_Company believes complaint relates to a discontinued policy or procedure',  'company_public_response_Company believes complaint represents an opportunity for improvement to better serve consumers',  'company_public_response_Company believes it acted appropriately as authorized by contract or law',  'company_public_response_Company believes the complaint is the result of a misunderstanding',  \"company_public_response_Company can't verify or dispute the facts in the complaint\",  'company_public_response_Company chooses not to provide a public response',  'company_public_response_Company disputes the facts presented in the complaint',  'company_public_response_Company has responded to the consumer and the CFPB and chooses not to provide a public response',  'company_code_AMERICAN EXPRESS COMPANY',  'company_code_Alliant Capital Management LLC',  'company_code_BANK OF AMERICA, NATIONAL ASSOCIATION',  'company_code_Blatt, Hasenmiller, Leibsker & Moore, LLC',  'company_code_CAPITAL ONE FINANCIAL CORPORATION',  'company_code_CITIBANK, N.A.',  'company_code_DISCOVER BANK',  'company_code_Ditech Financial LLC',  'company_code_ENCORE CAPITAL GROUP INC.',  'company_code_EQUIFAX, INC.',  'company_code_Experian Information Solutions Inc.',  'company_code_GOLDMAN SACHS BANK USA',  'company_code_HSBC NORTH AMERICA HOLDINGS INC.',  'company_code_JPMORGAN CHASE & CO.',  'company_code_LJ Ross Associates',  'company_code_NATIONSTAR MORTGAGE',  'company_code_Navient Solutions, LLC.',  'company_code_OCWEN LOAN SERVICING LLC',  'company_code_PNC Bank N.A.',  'company_code_PORTFOLIO RECOVERY ASSOCIATES INC',  'company_code_SELECT PORTFOLIO SERVICING, INC.',  'company_code_SUNTRUST BANKS, INC.',  'company_code_SYNCHRONY FINANCIAL',  'company_code_TD BANK US HOLDING COMPANY',  'company_code_TRANSUNION INTERMEDIATE HOLDINGS, INC.',  'company_code_U.S. BANCORP',  'company_code_WELLS FARGO & COMPANY',  'company_code_medium',  'company_code_petite',  'company_code_small',  'company_code_unique',  'consumer_consent_provided_Consent not provided',  'consumer_consent_provided_Consent provided',  'consumer_consent_provided_Consent withdrawn',  'consumer_consent_provided_Other',  'submitted_via_Email',  'submitted_via_Fax',  'submitted_via_Phone',  'submitted_via_Postal mail',  'submitted_via_Referral',  'submitted_via_Web',  'company_response_to_consumer_Closed',  'company_response_to_consumer_Closed with explanation',  'company_response_to_consumer_Closed with monetary relief',  'company_response_to_consumer_Closed with non-monetary relief',  'company_response_to_consumer_Closed with relief',  'company_response_to_consumer_Closed without relief',  'company_response_to_consumer_Untimely response',  'timely_response_Yes',]\n",
    "y=dispute_data[ 'consumer_disputed_Yes']\n",
    "#print(len(features),len(dispute_data.columns.tolist()))\n",
    "X=dispute_data[features]\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,test_size=0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# Create first pipeline for base without reducing features.\n",
    "\n",
    "pipe = Pipeline([('classifier' ,LogisticRegression(solver='liblinear',class_weight={0:.29, 1:.71}))])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 28.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 48.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__class_weight': 'balanced', 'classifier': LogisticRegression(C=0.0001, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear', 'classifier__C': 0.0001}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.27      0.41    247936\n",
      "           1       0.21      0.83      0.34     59471\n",
      "\n",
      "   micro avg       0.37      0.37      0.37    307407\n",
      "   macro avg       0.54      0.55      0.37    307407\n",
      "weighted avg       0.74      0.37      0.39    307407\n",
      "\n",
      "0.373859411139\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 5),\n",
    "    'classifier__solver' : ['liblinear'],\n",
    "    'classifier__class_weight':['balanced',{0: 0.4, 1: 0.6},{0: 0.31, 1: 0.69}]}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf_log = GridSearchCV(pipe, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf_log = clf_log.fit(train_X, train_y)\n",
    "\n",
    "print(clf_log.best_params_)\n",
    "y_true, y_pred_log = val_y, clf_log.predict(val_X)\n",
    "print(classification_report(y_true, y_pred_log))\n",
    "print(clf_log.score(val_X, val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 60 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 142.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': RandomForestClassifier(bootstrap=True, class_weight={0: 0.4, 1: 0.6},\n",
      "            criterion='gini', max_depth=None, max_features=95,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=90, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), 'classifier__max_features': 95, 'classifier__class_weight': {0: 0.4, 1: 0.6}, 'classifier__n_estimators': 90}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.88    247936\n",
      "           1       0.29      0.04      0.07     59471\n",
      "\n",
      "   micro avg       0.79      0.79      0.79    307407\n",
      "   macro avg       0.55      0.51      0.48    307407\n",
      "weighted avg       0.71      0.79      0.73    307407\n",
      "\n",
      "0.794994909029\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,20)),\n",
    "    'classifier__max_features' : list(range(65,105,10)),\n",
    "    'classifier__class_weight':['balanced',{0: 0.4, 1: 0.6},{0: 0.31, 1: 0.69}]}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf_for = GridSearchCV(pipe, param_grid = param_grid, cv = 2, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf_for= clf_for.fit(train_X, train_y)\n",
    "\n",
    "print(clf_for.best_params_)\n",
    "y_true, y_pred_for  = val_y, clf_for.predict(val_X)\n",
    "print(classification_report(y_true, y_pred_for))\n",
    "print(clf_for.score(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 12.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': DecisionTreeClassifier(class_weight={0: 0.4, 1: 0.6}, criterion='gini',\n",
      "            max_depth=1, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'classifier__class_weight': {0: 0.4, 1: 0.6}, 'classifier__max_depth': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89    247936\n",
      "           1       0.00      0.00      0.00     59471\n",
      "\n",
      "   micro avg       0.81      0.81      0.81    307407\n",
      "   macro avg       0.40      0.50      0.45    307407\n",
      "weighted avg       0.65      0.81      0.72    307407\n",
      "\n",
      "0.806539864089\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'classifier' : [DecisionTreeClassifier()],\n",
    "    'classifier__max_depth' : list(range(1,121,5)),\n",
    "    'classifier__class_weight':['balanced',{0: 0.4, 1: 0.6},{0: 0.35, 1: 0.55},{0: 0.31, 1: 0.69}]}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf_tree = GridSearchCV(pipe, param_grid = param_grid, cv = 2, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf_tree = clf_tree.fit(train_X, train_y)\n",
    "\n",
    "print(clf_tree.best_params_)\n",
    "y_true, y_pred_tree = val_y, clf_tree.predict(val_X)\n",
    "print(classification_report(y_true, y_pred_tree))\n",
    "print(clf_tree.score(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_iter': 5, 'classifier__penalty': 'elasticnet', 'classifier__loss': 'log', 'classifier': SGDClassifier(alpha=0.0001, average=False, class_weight={0: 0.4, 1: 0.6},\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=5,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False), 'classifier__class_weight': {0: 0.4, 1: 0.6}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89    247936\n",
      "           1       0.42      0.00      0.00     59471\n",
      "\n",
      "   micro avg       0.81      0.81      0.81    307407\n",
      "   macro avg       0.61      0.50      0.45    307407\n",
      "weighted avg       0.73      0.81      0.72    307407\n",
      "\n",
      "0.806533358056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "param_grid = [\n",
    "    {'classifier' : [SGDClassifier()],\n",
    "    'classifier__loss' : [\"hinge\",\"log\"],\n",
    "    'classifier__penalty':['l1','l2','elasticnet'],\n",
    "    'classifier__max_iter':[5,10],\n",
    "     'classifier__class_weight':['balanced',{0: 0.4, 1: 0.6},{0: 0.35, 1: 0.55},{0: 0.31, 1: 0.69}]}     \n",
    "]\n",
    "\n",
    "    \n",
    "SDcl = GridSearchCV(pipe, param_grid = param_grid, cv = 2, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_SDcl  = SDcl.fit(train_X, train_y)\n",
    "\n",
    "print(SDcl.best_params_)\n",
    "y_true, y_pred_SDcl = val_y, SDcl.predict(val_X)\n",
    "print(classification_report(y_true, y_pred_SDcl))\n",
    "print(SDcl.score(val_X, val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#SVC(C=1.0, kernel=’rbf’, gamma=’auto_deprecated’, class_weight=None)\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [SVC()],\n",
    "    'classifier__kernel' : [\"rbf\"],#,\"sigmoid\",'poly'],    'classifier__gamma':[\"auto_deprecated\",\"scale\"],\n",
    "    'classifier__class_weight':['balanced',{0: 0.3, 1: 0.7}]}     \n",
    "]\n",
    "\n",
    "    \n",
    "svccl = GridSearchCV(pipe, param_grid = param_grid, cv =2 , verbose=True)#, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_svccl  = svccl.fit(train_X, train_y)\n",
    "print(classification_report(y_true, y_pred_svccl))\n",
    "print(svccl.score(val_X, val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns to remove. []\n"
     ]
    }
   ],
   "source": [
    "# Threshold for removing correlated variables\n",
    "threshold = 0.9\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = X.corr().abs()\n",
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(to_drop)),to_drop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
